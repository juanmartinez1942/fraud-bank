{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7f7e5a",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582e88d",
   "metadata": {},
   "source": [
    "## 1. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6e2640",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from src.data_preprocessing import engineer_features, impute_missing_values\n",
    "from src.outlier_detection import remove_outliers_iqr\n",
    "from src.model_training import train_model\n",
    "from src.monitoring import check_drift, check_model_degradation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f4182",
   "metadata": {},
   "source": [
    "## 2. CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20210e87",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/fraud.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48939d",
   "metadata": {},
   "source": [
    "# 3. INGENIERIA DE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ac9886",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "target = 'isFraud'\n",
    "\n",
    "# Crear nuevas variables\n",
    "df = engineer_features(df)\n",
    "\n",
    "# Elegir columnas num√©ricas a imputar\n",
    "num_cols = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig',\n",
    "            'oldbalanceDest', 'newbalanceDest',\n",
    "            'balance_diff_orig', 'balance_diff_dest', 'amount_to_balance_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729913a2",
   "metadata": {},
   "source": [
    "## 3.1 IMPUTACION DE DATOS\n",
    "\n",
    "La imputaci√≥n de datos no se aplica adrede sino que requiere de un analisis del negocio concreto, la principal pregunta que ayuda a resolver que estrategia utilizar son:\n",
    "\n",
    "Qu√© significa para el negocio un valor nulo en x variable?\n",
    "\n",
    "Y de esa respuesta surgen las siguientes preguntas:\n",
    "\n",
    "Puede ser rellenada como un valor faltante?\n",
    "Puede ser rellenada con un valor calculado?\n",
    "Podemos quitar ese dato? La respuesta a esta pregunta es mas interna y la respondemos en base a si es un dato de fraude=True por ejemplo en este caso es relevante y quizas no es una opci√≥n quitarla porque nos esta brindando informacion, y en este caso esa informaci√≥n cobra relevancia porque es de la clase minoritaria.\n",
    "\n",
    "Y en base a eso decidimos que estrategia se adapta mejor mediante experimentaci√≥n para el entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb01d71",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Imputar\n",
    "X = df.drop(columns=['nameOrig', 'nameDest', 'isFraud', 'isFlaggedFraud'])  # sin IDs ni target\n",
    "y = df['isFraud']\n",
    "X = impute_missing_values(X, num_cols, save_path=\"models/imputer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff0be7f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "X.to_csv(\"data/fraud_dataset_encoded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a610de0",
   "metadata": {},
   "source": [
    "# 4. OUTLIER DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd8c612",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# OUTLIER DETECTION\n",
    "df_imputed = X.copy()\n",
    "df_imputed[target] = y\n",
    "df_filtered = remove_outliers_iqr(df_imputed, num_cols, target)\n",
    "\n",
    "X = df_filtered.drop(columns=target)\n",
    "y = df_filtered[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1f804",
   "metadata": {},
   "source": [
    "# 6. BALANCEO DE CLASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "124ffc83",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n original: isFraud\n",
      "0    2131605\n",
      "1       8213\n",
      "Name: count, dtype: int64\n",
      "Distribuci√≥n balanceada: isFraud\n",
      "0    8213\n",
      "1    8213\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juamp/miniconda3/envs/fraud_detection/lib/python3.9/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/juamp/miniconda3/envs/fraud_detection/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Distribuci√≥n original:\", y.value_counts())\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "print(\"Distribuci√≥n balanceada:\", y_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666448da",
   "metadata": {},
   "source": [
    "# 7. ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7269347",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model, X_train, X_test, y_train, y_test = train_model(X_resampled, y_resampled, save_path=\"models/rf_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1b309",
   "metadata": {},
   "source": [
    "# 8. EVALUACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c924c2",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluaci√≥n cruzada (5-fold):\n",
      "ROC_AUC   : 1.0000 ¬± 0.0000\n",
      "PRECISION : 0.9999 ¬± 0.0003\n",
      "RECALL    : 0.9994 ¬± 0.0004\n",
      "F1        : 0.9996 ¬± 0.0003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"precision\": make_scorer(precision_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"f1\": make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(model, X_resampled, y_resampled, cv=cv, scoring=scoring, return_train_score=False)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Mostrar m√©tricas promedio\n",
    "print(\"‚úÖ Evaluaci√≥n cruzada (5-fold):\")\n",
    "for metric in scoring.keys():\n",
    "    scores = results_df[f\"test_{metric}\"]\n",
    "    print(f\"{metric.upper():<10}: {scores.mean():.4f} ¬± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c931d1",
   "metadata": {},
   "source": [
    "## ‚úÖ Evaluaci√≥n del Modelo con Validaci√≥n Cruzada\n",
    "\n",
    "Se entren√≥ y evalu√≥ el modelo usando distintos grupos de datos para asegurarnos de que no solo funcione bien con un conjunto, sino que sea consistente en varios escenarios.\n",
    "\n",
    "### üìä Resultados Promedio (5 repeticiones):\n",
    "\n",
    "| M√©trica     | Resultado promedio | Qu√© significa |\n",
    "|-------------|--------------------|----------------|\n",
    "| **AUC**     | 1.0000 ¬± 0.0000     | El modelo distingue perfectamente entre transacciones normales y fraudulentas. |\n",
    "| **Precisi√≥n** | 0.9999 ¬± 0.0003     | Cuando el modelo predice fraude, casi siempre acierta. Muy pocos falsos positivos. |\n",
    "| **Recall**    | 0.9994 ¬± 0.0004     | Detecta pr√°cticamente todos los fraudes reales. Muy pocos se escapan. |\n",
    "| **F1 Score**  | 0.9996 ¬± 0.0003     | Excelente equilibrio entre precisi√≥n y cobertura de los fraudes. |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Conclusi√≥n\n",
    "\n",
    "El modelo demuestra un rendimiento **excepcional y muy estable**. A lo largo de m√∫ltiples pruebas, **detecta casi todos los fraudes sin generar muchas falsas alarmas**. Esto lo convierte en una soluci√≥n muy confiable para implementaci√≥n en producci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33efcd76",
   "metadata": {},
   "source": [
    "# 9. MONITOREO - SIMULACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5121bd",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_current = X_test.copy()\n",
    "df_current['isFraud'] = y_test.values\n",
    "baseline_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "drift_results = check_drift(df_current, X_train, num_cols)\n",
    "new_y_proba = model.predict_proba(df_current.drop(columns='isFraud'))[:, 1]\n",
    "perf_results = check_model_degradation(df_current['isFraud'], new_y_proba, baseline_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b74ad6",
   "metadata": {},
   "source": [
    "# 10. RESULTADOS MONITOREO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2163715f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Resultados de Drift:\n",
      "- step: Drift Score = 4.9717 | Drift Detectado: True\n",
      "- amount: Drift Score = 63731.1390 | Drift Detectado: True\n",
      "- oldbalanceOrg: Drift Score = 79221.4090 | Drift Detectado: True\n",
      "- newbalanceOrig: Drift Score = 15534.7028 | Drift Detectado: True\n",
      "- oldbalanceDest: Drift Score = 56711.4124 | Drift Detectado: True\n",
      "- newbalanceDest: Drift Score = 94877.4804 | Drift Detectado: True\n",
      "- balance_diff_orig: Drift Score = 64728.5591 | Drift Detectado: True\n",
      "- balance_diff_dest: Drift Score = 47520.9335 | Drift Detectado: True\n",
      "- amount_to_balance_ratio: Drift Score = 491.9837 | Drift Detectado: True\n",
      "\n",
      "üìâ Evaluaci√≥n de Desempe√±o:\n",
      "- AUC actual: 1.0000\n",
      "- Drop desde baseline: 0.0000\n",
      "- ¬øReentrenar? ‚ùå NO\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ Resultados de Drift:\")\n",
    "for col, result in drift_results.items():\n",
    "    print(f\"- {col}: Drift Score = {result['drift_score']:.4f} | Drift Detectado: {result['drifted']}\")\n",
    "\n",
    "print(\"\\nüìâ Evaluaci√≥n de Desempe√±o:\")\n",
    "print(f\"- AUC actual: {perf_results['current_auc']:.4f}\")\n",
    "print(f\"- Drop desde baseline: {perf_results['auc_drop']:.4f}\")\n",
    "print(f\"- ¬øReentrenar? {'‚úÖ S√ç' if perf_results['retrain'] else '‚ùå NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0ed63",
   "metadata": {},
   "source": [
    "# Armar archivo de monitoring_metrics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6587333",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulamos 30 d√≠as\n",
    "n_days = 30\n",
    "base_date = datetime.today() - timedelta(days=n_days)\n",
    "dates = [base_date + timedelta(days=i) for i in range(n_days)]\n",
    "\n",
    "# Generamos precisi√≥n y recall simulados\n",
    "precision = np.clip(np.random.normal(0.91, 0.03, n_days), 0.75, 0.99)\n",
    "recall = np.clip(np.random.normal(0.90, 0.04, n_days), 0.70, 0.99)\n",
    "\n",
    "# F1 Score (2 * P * R / (P + R))\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "data = {\n",
    "    \"date\": dates,\n",
    "    \"auc\": np.clip(np.random.normal(0.94, 0.02, n_days), 0.85, 0.99),\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1,\n",
    "    \"drift_score\": np.clip(np.random.normal(0.08, 0.04, n_days), 0.01, 0.25),\n",
    "}\n",
    "\n",
    "# Reentreno simulado\n",
    "data[\"retrain_triggered\"] = [\n",
    "    int(data[\"auc\"][i] < 0.88 or data[\"drift_score\"][i] > 0.15)\n",
    "    for i in range(n_days)\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"data/monitoring_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b259bf2c",
   "metadata": {},
   "source": [
    "# Armar graficos de SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac352a21",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Cargar modelo y datos\n",
    "model = joblib.load(\"models/rf_model.pkl\")\n",
    "\n",
    "# Calcular SHAP values globales\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Extraer SHAP values solo para la clase 1 \n",
    "shap_values_class_1 = shap_values[:, :, 1] \n",
    "\n",
    "# Bar plot\n",
    "import numpy as np\n",
    "\n",
    "# Media absoluta de los SHAP values para cada feature (global importance)\n",
    "importance = np.abs(shap_values_class_1).mean(axis=0)\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Guardar como CSV para uso en Streamlit\n",
    "df_shap_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "df_shap_importance.to_csv(\"data/shap_global_importance.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66205df0",
   "metadata": {},
   "source": [
    "# Prueba de diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d133831",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.9996956786366403, 'Balanced Accuracy': np.float64(0.9996956786366402), 'ROC AUC': np.float64(0.9996956786366402), 'F1 Score': 0.9996956786084568, 'Time taken': 0.4336071014404297}\n",
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.9996956786366403, 'Balanced Accuracy': np.float64(0.9996956786366402), 'ROC AUC': np.float64(0.9996956786366402), 'F1 Score': 0.9996956786084568, 'Time taken': 0.17564797401428223}\n",
      "{'Model': 'BernoulliNB', 'Accuracy': 0.7486305538648813, 'Balanced Accuracy': np.float64(0.7486305538648813), 'ROC AUC': np.float64(0.7486305538648813), 'F1 Score': 0.7368947360258079, 'Time taken': 0.015197992324829102}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'CalibratedClassifierCV', 'Accuracy': 0.95830797321972, 'Balanced Accuracy': np.float64(0.95830797321972), 'ROC AUC': np.float64(0.9583079732197202), 'F1 Score': 0.9582550506963626, 'Time taken': 0.2080059051513672}\n",
      "{'Model': 'DecisionTreeClassifier', 'Accuracy': 0.9996956786366403, 'Balanced Accuracy': np.float64(0.9996956786366402), 'ROC AUC': np.float64(0.9996956786366402), 'F1 Score': 0.9996956786084568, 'Time taken': 0.03367900848388672}\n",
      "{'Model': 'DummyClassifier', 'Accuracy': 0.5, 'Balanced Accuracy': np.float64(0.5), 'ROC AUC': np.float64(0.5), 'F1 Score': 0.3333333333333333, 'Time taken': 0.009619951248168945}\n",
      "{'Model': 'ExtraTreeClassifier', 'Accuracy': 0.9835666463785758, 'Balanced Accuracy': np.float64(0.9835666463785757), 'ROC AUC': np.float64(0.9835666463785758), 'F1 Score': 0.9835665915893667, 'Time taken': 0.01503896713256836}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesClassifier', 'Accuracy': 0.9942178940961656, 'Balanced Accuracy': np.float64(0.9942178940961656), 'ROC AUC': np.float64(0.9942178940961657), 'F1 Score': 0.9942178892767565, 'Time taken': 0.3470931053161621}\n",
      "{'Model': 'GaussianNB', 'Accuracy': 0.9321363359707852, 'Balanced Accuracy': np.float64(0.9321363359707852), 'ROC AUC': np.float64(0.9321363359707853), 'F1 Score': 0.931906277253291, 'Time taken': 0.011677265167236328}\n",
      "{'Model': 'KNeighborsClassifier', 'Accuracy': 0.9640900791235545, 'Balanced Accuracy': np.float64(0.9640900791235545), 'ROC AUC': np.float64(0.9640900791235544), 'F1 Score': 0.964066597842224, 'Time taken': 0.10783219337463379}\n",
      "{'Model': 'LabelPropagation', 'Accuracy': 0.8904443091905052, 'Balanced Accuracy': np.float64(0.8904443091905052), 'ROC AUC': np.float64(0.8904443091905052), 'F1 Score': 0.8896198052838725, 'Time taken': 1.8785762786865234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LabelSpreading', 'Accuracy': 0.888618381010347, 'Balanced Accuracy': np.float64(0.888618381010347), 'ROC AUC': np.float64(0.8886183810103471), 'F1 Score': 0.8877561724604315, 'Time taken': 2.985320806503296}\n",
      "{'Model': 'LinearDiscriminantAnalysis', 'Accuracy': 0.7997565429093122, 'Balanced Accuracy': np.float64(0.7997565429093122), 'ROC AUC': np.float64(0.7997565429093122), 'F1 Score': 0.7992191585841298, 'Time taken': 0.0441899299621582}\n",
      "{'Model': 'LinearSVC', 'Accuracy': 0.9528301886792453, 'Balanced Accuracy': np.float64(0.9528301886792452), 'ROC AUC': np.float64(0.9528301886792452), 'F1 Score': 0.9527277050657266, 'Time taken': 0.0846109390258789}\n",
      "{'Model': 'LogisticRegression', 'Accuracy': 0.9400486914181375, 'Balanced Accuracy': np.float64(0.9400486914181376), 'ROC AUC': np.float64(0.9400486914181376), 'F1 Score': 0.9398662428872735, 'Time taken': 0.037725210189819336}\n",
      "{'Model': 'NearestCentroid', 'Accuracy': 0.8037127206329885, 'Balanced Accuracy': np.float64(0.8037127206329884), 'ROC AUC': np.float64(0.8037127206329885), 'F1 Score': 0.8018452632213713, 'Time taken': 0.013532161712646484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'NuSVC', 'Accuracy': 0.857273280584297, 'Balanced Accuracy': np.float64(0.8572732805842971), 'ROC AUC': np.float64(0.857273280584297), 'F1 Score': 0.8558280489692977, 'Time taken': 4.0451531410217285}\n",
      "{'Model': 'PassiveAggressiveClassifier', 'Accuracy': 0.9446135118685332, 'Balanced Accuracy': np.float64(0.9446135118685332), 'ROC AUC': np.float64(0.9446135118685332), 'F1 Score': 0.9444947475064717, 'Time taken': 0.048752784729003906}\n",
      "{'Model': 'Perceptron', 'Accuracy': 0.9260499087035909, 'Balanced Accuracy': np.float64(0.9260499087035909), 'ROC AUC': np.float64(0.9260499087035909), 'F1 Score': 0.9260244161727615, 'Time taken': 0.01811695098876953}\n",
      "{'Model': 'QuadraticDiscriminantAnalysis', 'Accuracy': 0.9324406573341448, 'Balanced Accuracy': np.float64(0.9324406573341448), 'ROC AUC': np.float64(0.9324406573341449), 'F1 Score': 0.932426238655913, 'Time taken': 0.015197038650512695}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestClassifier', 'Accuracy': 0.9996956786366403, 'Balanced Accuracy': np.float64(0.9996956786366402), 'ROC AUC': np.float64(0.9996956786366402), 'F1 Score': 0.9996956786084568, 'Time taken': 0.7234041690826416}\n",
      "{'Model': 'RidgeClassifier', 'Accuracy': 0.7997565429093122, 'Balanced Accuracy': np.float64(0.7997565429093122), 'ROC AUC': np.float64(0.7997565429093122), 'F1 Score': 0.7992191585841298, 'Time taken': 0.02030634880065918}\n",
      "{'Model': 'RidgeClassifierCV', 'Accuracy': 0.7988435788192331, 'Balanced Accuracy': np.float64(0.7988435788192332), 'ROC AUC': np.float64(0.7988435788192331), 'F1 Score': 0.7983100935210345, 'Time taken': 0.025269031524658203}\n",
      "{'Model': 'SGDClassifier', 'Accuracy': 0.9354838709677419, 'Balanced Accuracy': np.float64(0.935483870967742), 'ROC AUC': np.float64(0.9354838709677419), 'F1 Score': 0.9352192957658464, 'Time taken': 0.03147006034851074}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVC', 'Accuracy': 0.9242239805234328, 'Balanced Accuracy': np.float64(0.9242239805234327), 'ROC AUC': np.float64(0.9242239805234328), 'F1 Score': 0.923892075190962, 'Time taken': 1.4781718254089355}\n",
      "{'Model': 'XGBClassifier', 'Accuracy': 0.9993913572732805, 'Balanced Accuracy': np.float64(0.9993913572732805), 'ROC AUC': np.float64(0.9993913572732804), 'F1 Score': 0.9993913572732805, 'Time taken': 0.12514615058898926}\n",
      "[LightGBM] [Info] Number of positive: 6570, number of negative: 6570\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2301\n",
      "[LightGBM] [Info] Number of data points in the train set: 13140, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:13<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMClassifier', 'Accuracy': 0.9990870359099209, 'Balanced Accuracy': np.float64(0.9990870359099209), 'ROC AUC': np.float64(0.9990870359099209), 'F1 Score': 0.99908703582537, 'Time taken': 0.22999882698059082}\n",
      "                        Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                    \n",
      "AdaBoostClassifier          1.00               1.00     1.00      1.00   \n",
      "BaggingClassifier           1.00               1.00     1.00      1.00   \n",
      "RandomForestClassifier      1.00               1.00     1.00      1.00   \n",
      "DecisionTreeClassifier      1.00               1.00     1.00      1.00   \n",
      "XGBClassifier               1.00               1.00     1.00      1.00   \n",
      "\n",
      "                        Time Taken  \n",
      "Model                               \n",
      "AdaBoostClassifier            0.43  \n",
      "BaggingClassifier             0.18  \n",
      "RandomForestClassifier        0.72  \n",
      "DecisionTreeClassifier        0.03  \n",
      "XGBClassifier                 0.13  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "import lazypredict.Supervised\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Forzar barra CLI en lugar de notebook\n",
    "lazypredict.Supervised.notebook_tqdm = tqdm\n",
    "lazypredict.Supervised.use_notebook_tqdm = False\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, stratify=y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Comparador de modelos\n",
    "clf = LazyClassifier(verbose=1, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Mostrar top 5 por ROC AUC\n",
    "print(models.sort_values(by=\"ROC AUC\", ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b3ba4",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusi√≥n de Selecci√≥n de Modelo\n",
    "\n",
    "### üîç Observaciones:\n",
    "\n",
    "- Todos los modelos top (`AdaBoost`, `Bagging`, `RandomForest`, `DecisionTree`, `XGBoost`) alcanzaron m√©tricas sobresalientes:\n",
    "  - **Accuracy**, **Balanced Accuracy**, **ROC AUC** y **F1 Score** ‚âà **1.00**\n",
    "  - Tiempos de entrenamiento muy bajos (< 1 segundo)\n",
    "- Esto sugiere que el conjunto de datos preprocesado y balanceado es **altamente separable**, lo cual es com√∫n en datasets simulados o bien estructurados. Aun que en proyectos reales rara vez nos encontramos con resultados as√≠\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclusi√≥n sobre el Mejor Modelo\n",
    "\n",
    "### üîç ¬øQu√© encontramos?\n",
    "\n",
    "Probamos varios modelos de predicci√≥n y todos obtuvieron resultados excelentes, con una precisi√≥n cercana al 100%. Esto indica que los datos con los que entrenamos el modelo permiten distinguir muy bien entre transacciones normales y fraudulentas.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Comparaci√≥n de Modelos\n",
    "\n",
    "| Modelo                 | ¬øQu√© lo hace bueno?                                              | ¬øQu√© tener en cuenta?                                      |\n",
    "|------------------------|------------------------------------------------------------------|-------------------------------------------------------------|\n",
    "| **Random Forest**      | Muy confiable, funciona bien con datos variados y poco limpios  | Un poco m√°s dif√≠cil de entender c√≥mo toma decisiones        |\n",
    "| **XGBoost**            | Muy potente y preciso, ideal si los datos son complejos          | M√°s t√©cnico y requiere ajustes finos                        |\n",
    "| **√Årbol de decisi√≥n**  | Muy f√°cil de entender, r√°pido                                    | Puede equivocarse si los datos cambian mucho                |\n",
    "| **AdaBoost**           | Combina varios modelos para hacerlo m√°s fuerte                   | Puede fallar si hay datos muy raros o extremos              |\n",
    "| **Bagging**            | Hace muchas versiones del mismo modelo y vota el resultado final | Puede usar m√°s recursos y ser m√°s lento                     |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Nuestra Elecci√≥n Final: `RandomForestClassifier`\n",
    "\n",
    "Se eligi√≥ **Random Forest** como el mejor modelo porque:\n",
    "\n",
    "- Tiene un rendimiento excelente en la predicci√≥n de fraudes.\n",
    "- Funciona bien incluso si los datos no son perfectos.\n",
    "- Es r√°pido de entrenar.\n",
    "- Se puede usar en producci√≥n y es compatible con herramientas para entender sus decisiones.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
